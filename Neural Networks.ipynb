{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn:package used to construct neural networks\n",
    "# torch.nn.Module:class of a standard neural network\n",
    "# torch.nn.Module.forward:function receiving input and returning output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x=x.view(-1,self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size=x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n",
    "net=Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0 torch.Size([6, 1, 5, 5])\n",
      "1 torch.Size([6])\n",
      "2 torch.Size([16, 6, 5, 5])\n",
      "3 torch.Size([16])\n",
      "4 torch.Size([120, 400])\n",
      "5 torch.Size([120])\n",
      "6 torch.Size([84, 120])\n",
      "7 torch.Size([84])\n",
      "8 torch.Size([10, 84])\n",
      "9 torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params=list(net.parameters())\n",
    "print(len(params))\n",
    "for i in range(len(params)):\n",
    "    print(i,params[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0307 -0.1047  0.1669 -0.0065 -0.0685 -0.1237 -0.0779  0.0646  0.0088 -0.0509\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0236\n",
      "-0.0901\n",
      " 0.0757\n",
      " 0.0030\n",
      "-0.0206\n",
      "-0.1038\n",
      "-0.1015\n",
      "-0.0445\n",
      " 0.0342\n",
      "-0.0825\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input=Variable(torch.randn(1,1,32,32))\n",
    "out=net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0324 -0.1073  0.1745  0.0062 -0.0734 -0.0894 -0.0694  0.0540  0.0169 -0.0713\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nSamples x nChannels x Height x Width\n",
    "input=Variable(torch.randn(1,1,32,32))\n",
    "out=net.forward(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "torch.Size([1, 1, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn only supports mini-batches The entire torch.nn package only supports inputs that are a mini-batch \n",
    "# of samples, and not a single sample.\n",
    "# If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.\n",
    "input1=Variable(torch.randn(3,32,32))\n",
    "input2=input.unsqueeze(0)\n",
    "print(input1.size())\n",
    "print(input2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.7372\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output=net(input)\n",
    "target=Variable(torch.arange(1,11))\n",
    "criterion=nn.MSELoss()\n",
    "loss=criterion(output,target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.MSELossBackward object at 0x7f6326604138>\n",
      "<torch.autograd.function.AddmmBackward object at 0x7f6326604048>\n",
      "<AccumulateGrad object at 0x7f6326610c50>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "conv1.bias.grad after backward\n",
      "Variable containing:\n",
      " 0.0277\n",
      " 0.0643\n",
      "-0.1082\n",
      " 0.1034\n",
      " 0.0223\n",
      "-0.0978\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using python code to update weights\n",
    "# learning_rate = 0.01\n",
    "# for f in net.parameters():\n",
    "#     f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pakage nn.optim to update weights\n",
    "import torch.optim as optim\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "output=net(input)\n",
    "loss=criterion(output,target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.0770  0.0213  0.0422  0.0961  0.0237\n",
      "  0.0302  0.1942 -0.0576  0.0028  0.1132\n",
      " -0.1761 -0.0682  0.0742 -0.0353  0.0586\n",
      " -0.0673 -0.0218  0.0274 -0.1235 -0.1659\n",
      " -0.1227  0.0029 -0.0429 -0.0480 -0.0906\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.0147 -0.0879 -0.1156 -0.1352  0.0526\n",
      "  0.0646 -0.0279 -0.1558  0.0222 -0.0439\n",
      "  0.0767  0.0798 -0.0347  0.0179 -0.0256\n",
      "  0.0736  0.0692  0.1238  0.0433 -0.1749\n",
      "  0.0727  0.0236 -0.0337 -0.1562 -0.0197\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  0.1164  0.1400 -0.0511 -0.0527 -0.0768\n",
      " -0.0369 -0.0507  0.0314 -0.0397  0.0786\n",
      " -0.0958 -0.1261  0.0616  0.0436  0.0549\n",
      " -0.0294 -0.0026  0.0527  0.0218 -0.0928\n",
      " -0.0001  0.0062  0.0994  0.0072 -0.0469\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      "  0.0297 -0.0655 -0.0469  0.0593  0.1417\n",
      "  0.0591 -0.0704  0.0744 -0.1173 -0.0800\n",
      "  0.0533  0.0006 -0.0336  0.0792  0.1015\n",
      " -0.0296  0.0588 -0.1722  0.1133  0.0514\n",
      "  0.1057  0.0512  0.0412 -0.0484 -0.0181\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      " -0.0304 -0.0079  0.0326 -0.0380 -0.0949\n",
      "  0.0658  0.0018  0.0317  0.0245 -0.1410\n",
      "  0.0116  0.0165  0.0228  0.0426 -0.0321\n",
      " -0.1130  0.0008  0.0017  0.0385  0.0196\n",
      "  0.0026 -0.0201  0.0151 -0.0078 -0.1106\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      " -0.1715  0.0909  0.0228  0.0396  0.0044\n",
      " -0.0909 -0.0231 -0.0182 -0.0679 -0.0363\n",
      "  0.0487 -0.1215 -0.0565 -0.0516 -0.0534\n",
      "  0.0143 -0.0009  0.0730  0.0057 -0.1121\n",
      " -0.1437 -0.0945  0.0274  0.0965  0.0050\n",
      "[torch.FloatTensor of size 6x1x5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
